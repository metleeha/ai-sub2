# 2019-09-03 두번째 스터디 _ 밑시딥 1권

## 1. 퍼셉트론 (이하동)

신호를 여러개를 받고, 합쳐서 하나로 출력하는 과정.

> H(x) = WX + B
>
> if H(x) > theta -> true
> else				-> false

퍼셉트론을 이용하면 AND, OR 게이트를 설명할 수 있음. 또한 이 게이트들을 논리회로 이론을 이용해서 결합하면 다양한 게이트를 만들 수 있었으나, 비선형적인 내용을 표현할 수 없었다.

## 2. 신경망 (황하남)

기존에 퍼셉트론은 가중치를 사람이 모두 정해주어야 했다. 그러면 W값을 학습시킬 뿐만 아니라 좋은 결과를 나올 수 있게 하는 방법이 뭐가 있을까에 대한 답으로 '신경망' 이론이 나옴.

신경망과 퍼셉트론의 차이는 가중치를 자동으로 구하는가의 여부, 그리고 

학습을 하기 위해서는 정답 Label과의 Error 값을 줄여가는 방향으로 진행한다. 에러를 구하는 방법에는 다양한 것이 있지만, MSE (Mean Squared Error)의 경우를 예시로 들면 mean( (Y - Y_pred)^2 ) 을 에러로 가지게 되면 Y와 Y_pred의 차이 값을 줄여갈 수 있도록.

그럼 줄여가는 방법은 어떻게 하는가?
'<b>Optimizer</b>', 가장 기본적인 이론은 <b>SGD (Stochastic Gradient Descent</b>) 을 사용한다.

## 3. 활성함수 (정해인)

퍼셉트론, 신경망에서는 입력으로 들어온 것과 가중치를 곱한 값을 특정 함수로 넘겨서 값을 구하는 과정으로 결과를 구한다. 이 특정 함수를 '<b>활성 함수</b>'라고 하며, 퍼셉트론에서는 계단 함수, 신경망으로 넘어가면서 Sigmoid 함수를 사용하게 되었다.

> Sigmoid(Z) = 1 / 1 + exp^-Z

Step, Sigmoid, ReLU

![KakaoTalk_20190903_141749018](https://user-images.githubusercontent.com/27988544/64145887-afe3e180-ce55-11e9-9e34-7ba6a324b898.jpg)

